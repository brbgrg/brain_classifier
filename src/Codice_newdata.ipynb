{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: c:\\Users\\barbo\\brain classifier repo\\brain_classifier\\src\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.getcwd()\n",
    "\n",
    "\n",
    "print(\"Base directory: {}\".format(base_dir))\n",
    "\n",
    "def load_mat_file(path):\n",
    "    \"\"\"Load a .mat file and return the loaded data.\"\"\"\n",
    "    data = scipy.io.loadmat(path)\n",
    "    return data\n",
    "\n",
    "# Function to save figures\n",
    "def save_figure(fig, filename, title=None):\n",
    "    directory = os.path.join(base_dir, \"Thesis Draft\", \"figures\")\n",
    "    report_file = os.path.join(base_dir, \"Thesis Draft\", \"reports\", \"report1.tex\")\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    fig_path = os.path.join(directory, filename)\n",
    "    fig.savefig(fig_path)\n",
    "\n",
    "    if title is None:\n",
    "        # Remove the file extension\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        # Replace underscores with spaces and capitalize each word\n",
    "        title = base_name.replace('_', ' ').title()\n",
    "\n",
    "    # Check if the figure path is already in the file\n",
    "    fig_include_str = fig_path.replace('\\\\', '/')\n",
    "    with open(report_file, 'r') as f:\n",
    "        content = f.read()\n",
    "        if fig_include_str in content:\n",
    "            return\n",
    "\n",
    "    # Add the figure to the summary file\n",
    "    with open(report_file, 'a') as f:\n",
    "        f.write(\"\\\\begin{figure}[h]\\n\")\n",
    "        f.write(\"\\\\centering\\n\")\n",
    "        f.write(\"\\\\includegraphics[width=0.8\\\\textwidth]{{{}}}\\n\".format(fig_path.replace('\\\\', '/')))\n",
    "        f.write(\"\\\\caption{{{}}}\\n\".format(title))\n",
    "        f.write(\"\\\\end{figure}\\n\\n\")\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\barbo\\\\brain classifier repo\\\\brain_classifier\\\\src'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mod_deg_zscore['fc_ya'].shape: (100, 101)\n",
      "mod_deg_zscore['fc_oa'].shape: (100, 78)\n",
      "part_coeff['fc_ya'].shape: (100, 101)\n",
      "part_coeff['fc_oa'].shape: (100, 78)\n"
     ]
    }
   ],
   "source": [
    "# Load connectivity data from .mat file\n",
    "data_path = os.path.join(base_dir, \"..\", \"new_data\", \"scfc_schaefer100_ya_oa.mat\")\n",
    "data = load_mat_file(data_path)\n",
    "\n",
    "# Load features from .mat files\n",
    "mod_deg_zscore_path = os.path.join(base_dir, \"..\", \"new_data\", \"mod_deg_zscore_scfc.mat\")\n",
    "part_coeff_path = os.path.join(base_dir, \"..\", \"new_data\", \"part_coeff_scfc.mat\")\n",
    "\n",
    "mod_deg_zscore_data = load_mat_file(mod_deg_zscore_path)\n",
    "part_coeff_data = load_mat_file(part_coeff_path)\n",
    "\n",
    "# Extract the content of the 'data' key\n",
    "data_content = data['data'][0, 0]\n",
    "\n",
    "\"\"\"\n",
    "# Print the fields in data_content\n",
    "print(\"data_content fields:\", data_content.dtype.names)\n",
    "# Check if any field names suggest age information\n",
    "for field in data_content.dtype.names:\n",
    "    print(f\"Field: {field}, Type: {type(data_content[field])}, Shape: {np.shape(data_content[field]) if hasattr(data_content[field], 'shape') else 'N/A'}\")\n",
    "\"\"\"\n",
    "\n",
    "# Extract the connectivity matrices and store them in a dictionary\n",
    "matrices = {\n",
    "    'sc_ya': np.array(data_content['sc_ya']),\n",
    "    'fc_ya': np.array(data_content['fc_ya']),\n",
    "    'sc_oa': np.array(data_content['sc_oa']),\n",
    "    'fc_oa': np.array(data_content['fc_oa'])\n",
    "}\n",
    "\n",
    "# Print the type and shape of the matrices\n",
    "\"\"\"\n",
    "for key, matrix in matrices.items():\n",
    "    print(f\"{key}: Type: {type(matrix)}, Shape: {matrix.shape}\") \n",
    "    # sc_ya: Type: <class 'numpy.ndarray'>, Shape: (100, 100, 101)\n",
    "    # fc_ya: Type: <class 'numpy.ndarray'>, Shape: (100, 100, 101)\n",
    "    # sc_oa: Type: <class 'numpy.ndarray'>, Shape: (100, 100, 78)\n",
    "    # fc_oa: Type: <class 'numpy.ndarray'>, Shape: (100, 100, 78)\n",
    "\"\"\"\n",
    "\n",
    "# Extract the age data and store them in a dictionary\n",
    "ages = {\n",
    "    'age_ya': np.array(data_content['age_ya']).flatten(),\n",
    "    'age_oa': np.array(data_content['age_oa']).flatten()\n",
    "}\n",
    "\n",
    "# assume first 101 columns are the ya features, last 78 are the oa features\n",
    "mod_deg_zscore = {\n",
    "    'fc_ya': np.array(mod_deg_zscore_data['mdz_fc'][:, :101]),\n",
    "    'fc_oa': np.array(mod_deg_zscore_data['mdz_fc'][:, 101:]),\n",
    "    'sc_ya': np.array(mod_deg_zscore_data['mdz_sc'][:, :101]),\n",
    "    'sc_oa': np.array(mod_deg_zscore_data['mdz_sc'][:, 101:])\n",
    "}\n",
    "\n",
    "part_coeff = {\n",
    "    'fc_ya': np.array(part_coeff_data['pc_fc'][:, :101]),\n",
    "    'fc_oa': np.array(part_coeff_data['pc_fc'][:, 101:]),\n",
    "    'sc_ya': np.array(part_coeff_data['pc_sc'][:, :101]),\n",
    "    'sc_oa': np.array(part_coeff_data['pc_sc'][:, 101:])\n",
    "}\n",
    "\n",
    "print(\"mod_deg_zscore['fc_ya'].shape:\", mod_deg_zscore['fc_ya'].shape)\n",
    "print(\"mod_deg_zscore['fc_oa'].shape:\", mod_deg_zscore['fc_oa'].shape)\n",
    "\n",
    "print(\"part_coeff['fc_ya'].shape:\", part_coeff['fc_ya'].shape)\n",
    "print(\"part_coeff['fc_oa'].shape:\", part_coeff['fc_oa'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age of young adults: 23.346534653465348, std: 2.6153985878927917\n",
      "Mean age of older adults: 70.01282051282051, std: 3.6461908108768544\n"
     ]
    }
   ],
   "source": [
    "# Print a histogram of the ages\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Young Adults\n",
    "ax[0].hist(ages['age_ya'], bins=20, color='blue', alpha=0.7)\n",
    "ax[0].set_title(\"Young Adults\")\n",
    "ax[0].set_xlabel(\"Age\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].set_xticks(np.unique(ages['age_ya']))\n",
    "\n",
    "# Older Adults\n",
    "ax[1].hist(ages['age_oa'], bins=20, color='red', alpha=0.7)\n",
    "ax[1].set_title(\"Older Adults\")\n",
    "ax[1].set_xlabel(\"Age\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[1].set_xticks(np.unique(ages['age_oa']))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print the mean and std of the ages\n",
    "print(f\"Mean age of young adults: {np.mean(ages['age_ya'])}, std: {np.std(ages['age_ya'])}\")\n",
    "print(f\"Mean age of older adults: {np.mean(ages['age_oa'])}, std: {np.std(ages['age_oa'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef check_properties(matrices):\\n    for key, matrix in matrices.items():\\n        age_group, matrix_type = key.split(\\'_\\')\\n        num_subjects = matrix.shape[2]\\n\\n        for i in range(num_subjects):\\n            symmetric = check_symetric(matrix[:, :, i])\\n            zero_diagonal = check_zero_diagonal(matrix[:, :, i])\\n            correct_shape = check_dimensions(matrix[:, :, i], (100, 100))\\n            \\n            if not symmetric or not zero_diagonal or not correct_shape:\\n                print(f\"{matrix_type.upper()} {age_group.capitalize()} Subject {i+1}:\")\\n                if not symmetric:\\n                    print(\" Not Symmetric \")\\n                if not zero_diagonal:\\n                    print(\" Diagonal is not Zero \")\\n                if not correct_shape:\\n                    print(\" Incorrect Shape \")\\n\\n# Check properties of matrices\\n\\ncheck_properties(matrices)\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feasibility of the matrices\n",
    "\n",
    "def check_symetric(matrix):\n",
    "    \"\"\"Check if a matrix is symmetric.\"\"\"\n",
    "    return np.allclose(matrix, matrix.T)\n",
    "\n",
    "def check_zero_diagonal(matrix):\n",
    "    \"\"\"Check if the diagonal of a matrix is zero.\"\"\"\n",
    "    return np.allclose(np.diag(matrix), 0)\n",
    "\n",
    "def check_dimensions(matrix, expected_shape=(100, 100)):\n",
    "    \"\"\"Check if the matrix has the expected shape.\"\"\"\n",
    "    return matrix.shape == expected_shape\n",
    "\n",
    "# Check the properties of the matrices\n",
    "\"\"\"\n",
    "def check_properties(matrices):\n",
    "    for key, matrix in matrices.items():\n",
    "        age_group, matrix_type = key.split('_')\n",
    "        num_subjects = matrix.shape[2]\n",
    "\n",
    "        for i in range(num_subjects):\n",
    "            symmetric = check_symetric(matrix[:, :, i])\n",
    "            zero_diagonal = check_zero_diagonal(matrix[:, :, i])\n",
    "            correct_shape = check_dimensions(matrix[:, :, i], (100, 100))\n",
    "            \n",
    "            if not symmetric or not zero_diagonal or not correct_shape:\n",
    "                print(f\"{matrix_type.upper()} {age_group.capitalize()} Subject {i+1}:\")\n",
    "                if not symmetric:\n",
    "                    print(\" Not Symmetric \")\n",
    "                if not zero_diagonal:\n",
    "                    print(\" Diagonal is not Zero \")\n",
    "                if not correct_shape:\n",
    "                    print(\" Incorrect Shape \")\n",
    "\n",
    "# Check properties of matrices\n",
    "\n",
    "check_properties(matrices)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing?\n",
    "\n",
    "\n",
    "# Convert matrices to graphs\n",
    "def matrix_to_graph(matrix):\n",
    "    \"\"\"Convert a matrix to a graph.\"\"\"\n",
    "    # matrix = np.array(matrix)\n",
    "    graph = nx.from_numpy_array(matrix) \n",
    "    return graph\n",
    "\n",
    "\n",
    "graphs = {}\n",
    "\n",
    "for key, matrix in matrices.items():\n",
    "    num_subjects = matrix.shape[2]\n",
    "    graphs[key] = [matrix_to_graph(matrix[:, :, i]) for i in range(num_subjects)] #list of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graphs\n",
    "\n",
    "# plot node degree histogram and distribution from https://github.com/gordicaleksa/pytorch-GAT/blob/main/The%20Annotated%20GAT%20(Cora).ipynb\n",
    "\n",
    "def plot_graph_on_axis(graph, ax, title, pos=None, partition=None):\n",
    "    \"\"\"Plot a graph on a given axis with node sizes proportional to the degree and edge widths proportional to the edge weights. \n",
    "        If partition is provided, nodes are colored by their community.\"\"\"\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Extract edge weights\n",
    "    edge_weights = [graph[u][v]['weight'] for u, v in graph.edges()]\n",
    "    # Apply min-max normalization for edge thickness\n",
    "    min_weight = min(edge_weights)\n",
    "    max_weight = max(edge_weights)\n",
    "    if min_weight != max_weight:  # Avoid division by zero\n",
    "        edge_weights = [(w - min_weight) / (max_weight - min_weight) for w in edge_weights]\n",
    "    else:\n",
    "        edge_weights = [1 for _ in edge_weights]  # If all weights are the same, set them to 1\n",
    "\n",
    "    # Calculate the degree of each node for node size\n",
    "    degrees = dict(graph.degree())\n",
    "    # Normalize the degrees to the range 0-1\n",
    "    max_degree = max(degrees.values())\n",
    "    min_degree = min(degrees.values())\n",
    "    normalized_degrees = {node: (degree - min_degree) / (max_degree - min_degree) for node, degree in degrees.items()}\n",
    "    # Set node sizes based on normalized degrees\n",
    "    node_sizes = [(normalized_degrees[node] + 0.1) * 5 for node in graph.nodes()]  \n",
    "\n",
    "    if partition:\n",
    "        # If partition is provided, color nodes by their community\n",
    "        cmap = plt.get_cmap('viridis', max(partition.values()) + 1)\n",
    "        node_color = list(partition.values())\n",
    "    else:\n",
    "        node_color = 'steelblue'\n",
    "    \n",
    "    # Draw the graph\n",
    "    if pos is None:\n",
    "        pos = nx.spring_layout(graph, seed=42)\n",
    "    nx.draw(graph, pos, ax=ax, node_size=node_sizes, with_labels=False, node_color=node_color, cmap=cmap if partition else None, edge_color='gray', width=edge_weights)\n",
    "\n",
    "    return pos\n",
    "\n",
    "\n",
    "def plot_and_save_graph(graphs, filename=None, positions=None, partitions=None, status=\"Original\", with_communities=False, num_subjects=1):\n",
    "    \"\"\"\n",
    "    Plot and save graphs for different age groups on a grid of subplots.\n",
    "    \n",
    "    Parameters:\n",
    "    - graphs: Dictionary containing NetworkX graphs for each age group and matrix type\n",
    "    - filename: name.png\n",
    "    - positions: List of positions for the graphs\n",
    "    - partitions: Dictionary containing partitions for the graphs of each age group and matrix type\n",
    "    - status: 'Original', 'Preprocessed', or 'Louvain Preprocessed'\n",
    "    - num_subjects: Number of subjects to plot (default is 1)\n",
    "    \"\"\"\n",
    "    community_text = \" with Louvain Communities\" if with_communities else \"\"\n",
    "    title = f'{status} Graphs{community_text}'\n",
    "    fig, axs = plt.subplots(4, num_subjects, figsize=(15, 9))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    if positions is None:\n",
    "        positions = {}\n",
    "    \n",
    "    if partitions is None:\n",
    "        partitions = {key: [None] * num_subjects for key in graphs.keys()}\n",
    "\n",
    "    # TODO\n",
    "    \"\"\"for j, (key, graph_list) in enumerate(graphs.items()):\n",
    "        age_group, matrix_type = key.split('_')\n",
    "        title_prefix = matrix_type.upper()\n",
    "        for i in range(min(num_subjects, len(graph_list))):\n",
    "            if len(positions.get(key, [])) > i:\n",
    "                pos = positions[key][i]\n",
    "                plot_graph_on_axis(graph_list[i], axs[j, i], f\"{key.upper()} Graph {i+1}\", pos, partitions[key][i] if partitions[key] else None)\n",
    "            else:\n",
    "                pos = plot_graph_on_axis(graph_list[i], axs[j, i], f\"{key.upper()} Graph {i+1}\", partition=partitions[key][i] if partitions[key] else None)\n",
    "                if key not in positions:\n",
    "                    positions[key] = []\n",
    "                positions[key].append(pos)\"\"\"\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    if filename:\n",
    "        save_figure(fig, filename, title)\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "    return positions\n",
    "\n",
    "\n",
    "\n",
    "# plot_and_save_graph(graphs, filename='graphs.png', status=' ', num_subjects=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.stats\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.utils.data import Dataset, random_split, Subset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topological measures that significantly change with age across the lifespan\n",
    "# different among structural and functional networks?\n",
    "\n",
    "# functional connectivity topological measures\n",
    "# from Cao 2014 \n",
    "# Local efficiency (inverted U shape) (sex differences only in global?)\n",
    "# Modularity (decrease linearly) ( without global signal regression modularity failed to detect age effects)\n",
    "# Mean connectivity strength (negative quadratic trajectories)\n",
    "# Normalized Rich Club coefficients (inverse U shape over a range of hub thresholds) (no significant sex differences)\n",
    "# Regional Functional Connectivity Strength (rFCS) (Age-related linear and quadratic changes both positive and negative) (male higher connectivity strength in some areas)\n",
    "# participation coefficient?\n",
    "# centrality measures? (sub-graph centrality)\n",
    "\n",
    "# structural connectivity topological measures\n",
    "\n",
    "# participation coefficient\n",
    "# contribution to modularity\n",
    "\n",
    "# matching index\n",
    "def calculate_connectivity_features(matrix, mod_deg_zscore, part_coeff, group):\n",
    "    \"\"\"Calculate node features from a connectivity matrix and additional features.\n",
    "    Features are from connectivity statistics: mean, standard deviation, kurtosis, skewness,\n",
    "    degree centrality of the node's connectivity vector to all the other nodes (Yang 2019),\n",
    "    modular degree z-score, and participation coefficient.\n",
    "    \"\"\"\n",
    "    num_subjects = len(mod_deg_zscore[group][0])\n",
    "    all_subjects_features = []\n",
    "\n",
    "    for s in range(num_subjects):\n",
    "        node_features = []\n",
    "        for i in range(matrix.shape[0] if matrix is not None else len(mod_deg_zscore[group])):\n",
    "            if 'sc' in group and matrix is not None:\n",
    "                # Structural features from connectivity statistics\n",
    "                connections = matrix[i, :, s]\n",
    "                connections = connections.flatten()\n",
    "                mean = connections.mean()\n",
    "                std = connections.std()\n",
    "                skew = scipy.stats.skew(connections)\n",
    "                kurtosis = scipy.stats.kurtosis(connections)\n",
    "                # Additional features\n",
    "                mod_deg = mod_deg_zscore[group][i, s]\n",
    "                part_coef = part_coeff[group][i, s]\n",
    "                # Calculate degree centrality\n",
    "                node_features.append([mean, std, skew, kurtosis, mod_deg, part_coef])\n",
    "            else:\n",
    "                # Only mod_deg_zscore and participation coefficient for functional graphs or if matrix is None\n",
    "                mod_deg = mod_deg_zscore[group][i, s]\n",
    "                part_coef = part_coeff[group][i, s]\n",
    "                node_features.append([mod_deg, part_coef])\n",
    "        \n",
    "        # Convert the list of lists to a numpy array before converting to a tensor\n",
    "        node_features = np.array(node_features)\n",
    "        all_subjects_features.append(torch.tensor(node_features, dtype=torch.float32))\n",
    "    \n",
    "    return all_subjects_features\n",
    "\n",
    "\n",
    "#TODO: Capire se c' variabilit nelle feature (valori medi, istogramma)\n",
    "# dimensionality reduction (PCA, autoencoders) or feature selections to decrease the number of features?\n",
    "\n",
    "def combined_graph(matrix, feature_tensor=None, feature_type='random'):\n",
    "    \"\"\"Combine a connectivity matrix and a feature tensor into a single graph.\n",
    "    Graphs are constructed from the connectivity matrix and the node features \n",
    "    consist of the provided feature tensor. If feature_tensor is not provided,\n",
    "    the user can choose between using a random tensor or an identity tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - matrix: The connectivity matrix.\n",
    "    - feature_tensor: List of feature tensors. If None, feature_type is used.\n",
    "    - feature_type: The type of tensor to use if feature_tensor is None. Options are 'random' or 'identity'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Turn matrix into torch tensor\n",
    "    tensor_matrix = torch.tensor(matrix, dtype=torch.float)\n",
    "\n",
    "    # Initialize empty list for storing graph data objects\n",
    "    graph_list = []\n",
    "\n",
    "    # Determine the number of subjects and nodes\n",
    "    num_subjects = tensor_matrix.shape[2]\n",
    "    num_nodes = tensor_matrix.shape[0]\n",
    "\n",
    "    # Generate feature tensor if not provided\n",
    "    if feature_tensor is None:\n",
    "        if feature_type == 'random':\n",
    "            feature_tensor = [torch.rand((num_nodes, 4), dtype=torch.float32) for _ in range(num_subjects)]\n",
    "        elif feature_type == 'identity':\n",
    "            feature_tensor = [torch.eye(num_nodes, dtype=torch.float32) for _ in range(num_subjects)]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid feature_type. Choose 'random' or 'identity'.\")\n",
    "    # create edge and edge weight lists for each subject\n",
    "    for i in range(num_subjects):\n",
    "        # Set edges for the graph as in tensor_matrix\n",
    "        edges = []\n",
    "        edge_weights = []\n",
    "        for j in range(num_nodes):\n",
    "            for k in range(j+1, num_nodes):\n",
    "                weight = tensor_matrix[j, k, i]\n",
    "                # Remove null edges? (Yang doesn't)  \n",
    "                # Add both directions since undirected?\n",
    "                if weight != 0:  # Remove null edges\n",
    "                    edges.append([j, k])\n",
    "                    edges.append([k, j])\n",
    "                    edge_weights.append(weight)\n",
    "                    edge_weights.append(weight)\n",
    "\n",
    "        # Convert graph edges in form of torch tensor of size (2, num_edges)\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous() \n",
    "\n",
    "        # Convert graph edge weights in form of torch tensor \n",
    "        edge_weights = torch.tensor(edge_weights, dtype=torch.float32)\n",
    "\n",
    "        # Create graph data object\n",
    "        data = Data(x=feature_tensor[i], edge_index=edge_index, edge_attr=edge_weights)\n",
    "        \n",
    "        # Append the graph data object to the list\n",
    "        graph_list.append(data)\n",
    "\n",
    "    return graph_list\n",
    "\n",
    "\n",
    "# Calculate node features for both structural and functional matrices\n",
    "features = {\n",
    "   # 'sc_ya': calculate_connectivity_features(matrices['sc_ya'], mod_deg_zscore, part_coeff, 'sc_ya'),\n",
    "   # 'sc_oa': calculate_connectivity_features(matrices['sc_oa'], mod_deg_zscore, part_coeff, 'sc_oa'),\n",
    "   # 'fc_ya': calculate_connectivity_features(matrices['fc_ya'], mod_deg_zscore, part_coeff, 'fc_ya'),\n",
    "   # 'fc_oa': calculate_connectivity_features(matrices['fc_oa'], mod_deg_zscore, part_coeff, 'fc_oa'),\n",
    "    'combined_ya': calculate_connectivity_features(matrices['sc_ya'], mod_deg_zscore, part_coeff, 'fc_ya'),\n",
    "    'combined_oa': calculate_connectivity_features(matrices['sc_oa'], mod_deg_zscore, part_coeff, 'fc_oa')\n",
    "}\n",
    "\n",
    "# Each element is a list of graph data objects\n",
    "#TODO: stack functional and structural features together?\n",
    "#TODO: using multi-edge connections instead of separate modalities?\n",
    "combined_graphs = {\n",
    "  #  'sc_ya': combined_graph(matrices['sc_ya'], feature_tensor=features['sc_ya']),\n",
    "   # 'sc_oa': combined_graph(matrices['sc_oa'], feature_tensor=features['sc_oa']),\n",
    "    #'fc_ya': combined_graph(matrices['fc_ya'], feature_tensor=features['fc_ya']),\n",
    "    #'fc_oa': combined_graph(matrices['fc_oa'], feature_tensor=features['fc_oa']),\n",
    "    'fc_sc_ya': combined_graph(matrices['fc_ya'], feature_tensor=features['combined_ya']),\n",
    "    'fc_sc_oa': combined_graph(matrices['fc_oa'], feature_tensor=features['combined_oa']),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[100, 2], edge_index=[2, 9900], edge_attr=[9900])\n"
     ]
    }
   ],
   "source": [
    "print(combined_graphs['fc_sc_ya'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the len of the combined graphs\n",
    "\n",
    "\n",
    "graphs_sc = combined_graphs['sc_ya']+combined_graphs['sc_oa']\n",
    "labels_sc = [0]*len(combined_graphs['sc_ya']) + [1]*len(combined_graphs['sc_oa'])\n",
    "#dataset_sc = list(zip(graphs_sc, labels_sc))\n",
    "\n",
    "\n",
    "graphs_fc_sc = combined_graphs['fc_sc_ya']+combined_graphs['fc_sc_oa']\n",
    "labels_fc_sc = [0]*len(combined_graphs['fc_sc_ya']) + [1]*len(combined_graphs['fc_sc_oa'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barbo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_sc len: 125, type: <class 'list'>\n",
      "test_data_sc len: 54, type: <class 'list'>\n",
      "train_labels_sc len: 125, type: <class 'list'>\n",
      "test_labels_sc len: 54, type: <class 'list'>\n",
      "train_data_sc[0] shape: torch.Size([100, 4])\n",
      "train_data_sc[0] edge_index shape: torch.Size([2, 3460])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data with stratification\n",
    "train_data_sc, test_data_sc, train_labels_sc, test_labels_sc = train_test_split(graphs_sc, labels_sc, test_size=0.3, random_state=42, stratify=labels_sc)\n",
    "#train_data_fc_sc, test_data_fc_sc, train_labels_fc_sc, test_labels_fc_sc = train_test_split(graphs_fc_sc, labels_fc_sc, test_size=0.3, random_state=42, stratify=labels_fc_sc)\n",
    "# train_data_fc, test_data_fc, train_labels_fc, test_labels_fc = train_test_split(graphs_fc, labels_fc, test_size=0.3, random_state=42, stratify=labels_fc)\n",
    "\n",
    "# Print the shapes of the split data\n",
    "\n",
    "print(f'train_data_sc len: {len(train_data_sc)}, type: {type(train_data_sc)}') \n",
    "print(f'test_data_sc len: {len(test_data_sc)}, type: {type(test_data_sc)}')\n",
    "print(f'train_labels_sc len: {len(train_labels_sc)}, type: {type(train_labels_sc)}')\n",
    "print(f'test_labels_sc len: {len(test_labels_sc)}, type: {type(test_labels_sc)}')\n",
    "\n",
    "\n",
    "# print the shape of the first element in the train_data_sc\n",
    "print(f'train_data_sc[0] shape: {train_data_sc[0].x.shape}')\n",
    "print(f'train_data_sc[0] edge_index shape: {train_data_sc[0].edge_index.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_sc len: 125\n",
      "test_dataset_sc len: 54\n",
      "graph shape: torch.Size([100, 4]), label: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch dataset as a subclass of torch.utils.data.Dataset\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graphs, labels):\n",
    "        self.graphs = graphs # list of graphs (Data objects)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        label = self.labels[idx]\n",
    "        return graph, label\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset_sc = GraphDataset(train_data_sc, train_labels_sc)\n",
    "test_dataset_sc = GraphDataset(test_data_sc, test_labels_sc)\n",
    "\n",
    "\n",
    "#train_dataset_fc_sc = GraphDataset(train_data_fc_sc, train_labels_fc_sc)\n",
    "#test_dataset_fc_sc = GraphDataset(test_data_fc_sc, test_labels_fc_sc)\n",
    "\n",
    "# train_dataset_fc = GraphDataset(train_data_fc, train_labels_fc)\n",
    "# test_dataset_fc = GraphDataset(test_data_fc, test_labels_fc)\n",
    "\n",
    "\n",
    "# Print the length of the datasets\n",
    "\n",
    "print(f'train_dataset_sc len: {len(train_dataset_sc)}')\n",
    "print(f'test_dataset_sc len: {len(test_dataset_sc)}')\n",
    "\n",
    "# print the first element of the train_dataset_sc\n",
    "graph, label = train_dataset_sc[0]\n",
    "print(f'graph shape: {graph.x.shape}, label: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader_sc len: 4\n",
      "data len: 32, labels len: 32\n",
      "data[0] shape: torch.Size([100, 4]), labels[0]: 1\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader_sc = DataLoader(train_dataset_sc, batch_size=batch_size, shuffle=True)\n",
    "test_loader_sc = DataLoader(test_dataset_sc, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\"\"\"\n",
    "train_loader_fc_sc = DataLoader(train_dataset_fc_sc, batch_size=batch_size, shuffle=True)\n",
    "test_loader_fc_sc = DataLoader(test_dataset_fc_sc, batch_size=batch_size, shuffle=False)\n",
    "\"\"\"\n",
    "# train_loader_fc = DataLoader(train_dataset_fc, batch_size=batch_size, shuffle=True)\n",
    "# test_loader_fc = DataLoader(test_dataset_fc, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "print(f'train_loader_sc len: {len(train_loader_sc)}')\n",
    "\n",
    "# print the length of the first element in the train_loader_sc\n",
    "for data, labels in train_loader_sc:\n",
    "    print(f'data len: {len(data)}, labels len: {len(labels)}')\n",
    "    print(f'data[0] shape: {data[0].x.shape}, labels[0]: {labels[0]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# GAT model\n",
    "# Interpretable graph classification\n",
    "# Captum for interpretability?\n",
    "# https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py\n",
    "\n",
    "#--------------------------------\n",
    "# Device configuration\n",
    "#--------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: %s' % device)\n",
    "\n",
    "#--------------------------------\n",
    "# Hyper-parameters\n",
    "#--------------------------------\n",
    "in_channels = 4\n",
    "out_channels = 8\n",
    "num_classes = 2\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 1e-1\n",
    "learning_rate_decay = 0.95\n",
    "reg = 0.001\n",
    "num_training = 125\n",
    "num_test = 54\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads=1):  # hidden_channels\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, out_channels, heads=heads, concat=True, dropout=0.6)\n",
    "        self.classifier = nn.Linear(out_channels * heads, num_classes)  # Adjust output size based on concatenation\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)  # x = F.elu(x)\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        x = self.classifier(x)\n",
    "        return x  # shape = (num_nodes, num_classes)\n",
    "\n",
    "# Initialize model, criterion and optimizer\n",
    "model = GAT(in_channels=in_channels, out_channels=out_channels, heads=1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # weight_decay=reg)\n",
    "\n",
    "# Training function\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # forward pass\n",
    "        out = model(data)\n",
    "        # compute loss\n",
    "        loss = criterion(out, labels)\n",
    "        # zero the gradients to prevent accumulation\n",
    "        optimizer.zero_grad()\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        # accumulate loss\n",
    "        total_loss += loss.item()\n",
    "    # average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# Evaluation function\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=-1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.1071, Test Accuracy: 55.56%\n",
      "Epoch [2/20], Loss: 1.0420, Test Accuracy: 44.44%\n",
      "Epoch [3/20], Loss: 0.7430, Test Accuracy: 55.56%\n",
      "Epoch [4/20], Loss: 0.8015, Test Accuracy: 44.44%\n",
      "Epoch [5/20], Loss: 0.7499, Test Accuracy: 44.44%\n",
      "Epoch [6/20], Loss: 0.7088, Test Accuracy: 55.56%\n",
      "Epoch [7/20], Loss: 0.7126, Test Accuracy: 55.56%\n",
      "Epoch [8/20], Loss: 0.6908, Test Accuracy: 44.44%\n",
      "Epoch [9/20], Loss: 0.6967, Test Accuracy: 55.56%\n",
      "Epoch [10/20], Loss: 0.6963, Test Accuracy: 55.56%\n",
      "Epoch [11/20], Loss: 0.6821, Test Accuracy: 55.56%\n",
      "Epoch [12/20], Loss: 0.6854, Test Accuracy: 55.56%\n",
      "Epoch [13/20], Loss: 0.6836, Test Accuracy: 55.56%\n",
      "Epoch [14/20], Loss: 0.6810, Test Accuracy: 55.56%\n",
      "Epoch [15/20], Loss: 0.6814, Test Accuracy: 55.56%\n",
      "Epoch [16/20], Loss: 0.6814, Test Accuracy: 55.56%\n",
      "Epoch [17/20], Loss: 0.6827, Test Accuracy: 55.56%\n",
      "Epoch [18/20], Loss: 0.6829, Test Accuracy: 55.56%\n",
      "Epoch [19/20], Loss: 0.6824, Test Accuracy: 55.56%\n",
      "Epoch [20/20], Loss: 0.6839, Test Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "# Epoch loop with prints\n",
    "lr = learning_rate  # Initialize learning rate\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(train_loader_sc)\n",
    "    test_accuracy = test(test_loader_sc)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    # Code to update the lr\n",
    "    #lr *= learning_rate_decay\n",
    "    #update_lr(optimizer, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload new Puxeddu data\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "# This website has got some awesome visualizations check it out:\n",
    "# http://networkrepository.com/graphvis.php?d=./data/gsm50/labeled/cora.edges\n",
    "\n",
    "#https://towardsdatascience.com/large-graph-visualization-tools-and-approaches-2b8758a1cd59\n",
    "\n",
    "# igraph "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
